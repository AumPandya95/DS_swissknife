{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entertaining-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import timeit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expected-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/aumaron/Desktop/other_projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hairy-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "rf = pd.read_excel(\"datasets/o_ring_failure_wiith_constant.xlsx\", engine=\"openpyxl\")\n",
    "ring_failure = pd.read_excel(\"datasets/o_ring_failure.xlsx\", engine=\"openpyxl\")\n",
    "# ring_failure.dropna(how=\"all\", subset=[\"Target (Total orders)\"], inplace=True)\n",
    "\n",
    "# ring_failure.fillna(demand_forecast.mean(), inplace=True)\n",
    "\n",
    "print(ring_failure.shape)\n",
    "target = np.array(ring_failure.loc[:, \"number_experiencing_thermal_distress\"])\n",
    "ring_failure.drop(columns=[\"number_experiencing_thermal_distress\"], inplace=True)\n",
    "train_array = np.array(ring_failure)\n",
    "\n",
    "target1 = np.array(rf.loc[:, \"number_experiencing_thermal_distress\"])\n",
    "rf.drop(columns=[\"number_experiencing_thermal_distress\"], inplace=True)\n",
    "train_array1 = np.array(rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-joshua",
   "metadata": {},
   "source": [
    "### Linear Model without intercept (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression sklearn\n",
    "lm_sk = linear_model.LinearRegression(fit_intercept=False)  # Taking the first column with var=0 as the constant column\n",
    "lm_sk.fit(train_array, target)\n",
    "print(lm_sk.coef_)\n",
    "print(lm_sk.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression sklearn\n",
    "lm_sk = linear_model.LinearRegression(fit_intercept=False)  # Taking the first column with var=0 as the constant column\n",
    "lm_sk.fit(train_array1, target1)\n",
    "print(lm_sk.coef_)\n",
    "print(lm_sk.intercept_, \"\\n\")\n",
    "\n",
    "#Linear Regression sklearn\n",
    "lm_sk = linear_model.LinearRegression(fit_intercept=True)  # Taking the first column with var=0 as the constant column\n",
    "lm_sk.fit(train_array1, target1)\n",
    "print(lm_sk.coef_)\n",
    "print(lm_sk.intercept_, \"\\n\")\n",
    "\n",
    "\n",
    "lm_sk = linear_model.LinearRegression(fit_intercept=True)  # Taking the first column with var=0 as the constant column\n",
    "lm_sk.fit(train_array1[:, 1:4], target1)\n",
    "print(lm_sk.coef_)\n",
    "print(lm_sk.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression statsmodel\n",
    "import statsmodels.api as sm\n",
    "# train_array = np.column_stack((train_array, np.ones(train_array.shape[0])))\n",
    "train_array_new = sm.add_constant(train_array1[:, 1:4], has_constant=\"add\")\n",
    "lm_st = sm.OLS(target, train_array_new).fit()\n",
    "print(lm_st.params)\n",
    "lm_st.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-chick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear regression statsmodel\n",
    "import statsmodels.api as sm\n",
    "# train_array = np.column_stack((train_array, np.ones(train_array.shape[0])))\n",
    "lm_st = sm.OLS(target, train_array)\n",
    "result = lm_st.fit()\n",
    "print(result.params)\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-projector",
   "metadata": {},
   "source": [
    "### Model with Intercept (without penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "czech-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05138594  0.00175701  0.01429284]\n",
      "3.527093383307082\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression sklearn\n",
    "lm_sk = linear_model.LinearRegression()\n",
    "lm_sk.fit(train_array, target)\n",
    "print(lm_sk.coef_)\n",
    "print(lm_sk.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "concrete-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.52709338e+00 -5.13859399e-02  1.75700897e-03  1.42928426e-02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 03 May 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0337</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:38:11</td>     <th>  Log-Likelihood:    </th> <td> -17.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    23</td>      <th>  AIC:               </th> <td>   42.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   47.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.5271</td> <td>    1.307</td> <td>    2.699</td> <td> 0.014</td> <td>    0.791</td> <td>    6.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0514</td> <td>    0.018</td> <td>   -2.802</td> <td> 0.011</td> <td>   -0.090</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0018</td> <td>    0.003</td> <td>    0.517</td> <td> 0.611</td> <td>   -0.005</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0143</td> <td>    0.035</td> <td>    0.407</td> <td> 0.689</td> <td>   -0.059</td> <td>    0.088</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.300</td> <th>  Durbin-Watson:     </th> <td>   2.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  18.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.686</td> <th>  Prob(JB):          </th> <td>8.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.881</td> <th>  Cond. No.          </th> <td>1.98e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.98e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.360\n",
       "Model:                            OLS   Adj. R-squared:                  0.259\n",
       "Method:                 Least Squares   F-statistic:                     3.563\n",
       "Date:                Mon, 03 May 2021   Prob (F-statistic):             0.0337\n",
       "Time:                        23:38:11   Log-Likelihood:                -17.308\n",
       "No. Observations:                  23   AIC:                             42.62\n",
       "Df Residuals:                      19   BIC:                             47.16\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.5271      1.307      2.699      0.014       0.791       6.263\n",
       "x1            -0.0514      0.018     -2.802      0.011      -0.090      -0.013\n",
       "x2             0.0018      0.003      0.517      0.611      -0.005       0.009\n",
       "x3             0.0143      0.035      0.407      0.689      -0.059       0.088\n",
       "==============================================================================\n",
       "Omnibus:                       17.300   Durbin-Watson:                   2.392\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.847\n",
       "Skew:                           1.686   Prob(JB):                     8.08e-05\n",
       "Kurtosis:                       5.881   Cond. No.                     1.98e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.98e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression statsmodel\n",
    "import statsmodels.api as sm\n",
    "# train_array = np.column_stack((train_array, np.ones(train_array.shape[0])))\n",
    "train_array_new = sm.add_constant(train_array, has_constant=\"add\")\n",
    "lm_st = sm.OLS(target, train_array_new).fit()\n",
    "print(lm_st.params)\n",
    "lm_st.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-oregon",
   "metadata": {},
   "source": [
    "### Model with intercept (lasso penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_new = sm.add_constant(train_array, has_constant=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "unable-expansion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.00149013  0.00313455 -0.        ]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression sklearn\n",
    "lm_lasso_sk = linear_model.Lasso(alpha=1, fit_intercept=False, positive=False)\n",
    "lm_lasso_sk.fit(train_array_new, target)\n",
    "print(lm_lasso_sk.coef_)\n",
    "print(lm_lasso_sk.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "embedded-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.0025622 0.       ]\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression sklearn\n",
    "lm_elasti_sk = linear_model.ElasticNet(l1_ratio=1, alpha=1, fit_intercept=False, positive=True)\n",
    "lm_elasti_sk.fit(train_array_new, target)\n",
    "print(lm_elasti_sk.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "plastic-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.0025622 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression statsmodel\n",
    "import statsmodels.api as sm\n",
    "lm_st = sm.OLS(target, train_array_new)\n",
    "result = lm_st.fit()\n",
    "# print(result.params)\n",
    "# result.summary()\n",
    "# Lasso\n",
    "results_fr = lm_st.fit_regularized(method=\"elastic_net\", alpha=1, L1_wt=1, start_params=result.params)\n",
    "# final = sm.regression.linear_model.OLSResults(lm_st,\n",
    "#                                               results_fr.params, \n",
    "#                                               lm_st.normalized_cov_params)\n",
    "print(results_fr.params)\n",
    "# final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-bench",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-leeds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-monster",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
